import streamlit as st
import requests
from lxml import html
import re
from urllib.parse import quote
import pandas as pd  # ë°ì´í„°í”„ë ˆì„ í™œìš©ì„ ìœ„í•´ ì¶”ê°€

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì „ìë„ì„œê´€ í†µí•©ê²€ìƒ‰", page_icon="ğŸ“š")

# (ì¤‘ëµ: libraries ë°ì´í„° ë° search_libraries í•¨ìˆ˜ëŠ” ì‚¬ìš©ìë‹˜ì˜ ìµœì¢… ë²„ì „ ìœ ì§€)
# ë‹¨, search_libraries ê²°ê³¼ì—ì„œ HTML íƒœê·¸(<a href...>)ë¥¼ ì œê±°í•˜ê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ì™€ ë§í¬ URLë§Œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

def search_libraries(book_name):
    results = []
    progress_bar = st.progress(0)
    total = len(libraries)

    for i, lib in enumerate(libraries):
        progress_bar.progress((i + 1) / total)
        try:
            encoded_query = quote(book_name.encode(lib["encoding"]))
            search_url = f"{lib['url']}?{lib['key_param']}={encoded_query}"
            if lib["type"] == "standard" or lib["type"] == "ink": 
                search_url += "&schClst=ctts%2Cautr&schDvsn=001"
            elif lib["type"] == "gangnam": 
                search_url += "&search=title"

            resp = requests.get(search_url, timeout=5)
            count = 0
            if resp.status_code == 200:
                tree = html.fromstring(resp.content)
                nodes = tree.xpath(lib["xpath"])
                if nodes:
                    count_match = re.findall(r'\d+', "".join(nodes))
                    count = int(count_match[0]) if count_match else 0
            
            display = f"{count}ê¶Œ" if count > 0 else "ì—†ìŒ"
            results.append({"ë„ì„œê´€": lib['name'], "ìƒíƒœ": display, "ë§í¬": search_url})
        except:
            results.append({"ë„ì„œê´€": lib['name'], "ìƒíƒœ": "í™•ì¸ë¶ˆê°€", "ë§í¬": "#"})

    # ì§ì ‘ í™•ì¸ ë„ì„œê´€ ì¶”ê°€
    encoded_utf8 = quote(book_name.encode("utf-8"))
    direct_links = [
        {"ë„ì„œê´€": "ì„œìš¸ë„ì„œê´€", "ìƒíƒœ": "ë§í¬ í™•ì¸", "ë§í¬": f"https://elib.seoul.go.kr/contents/search/content?t=EB&k={encoded_utf8}"},
        {"ë„ì„œê´€": "ì„œì´ˆêµ¬", "ìƒíƒœ": "ë§í¬ í™•ì¸", "ë§í¬": f"https://e-book.seocholib.or.kr/search?keyword={encoded_utf8}"},
        {"ë„ì„œê´€": "ë¶€ì²œì‹œ", "ìƒíƒœ": "ë§í¬ í™•ì¸", "ë§í¬": f"https://ebook.bcl.go.kr:444/elibrary-front/search/searchList.ink?schTxt={encoded_utf8}&schClst=ctts%2Cautr&schDvsn=001"}
    ]
    results.extend(direct_links)
    
    progress_bar.empty()
    return results

# í™”ë©´ êµ¬ì„±
st.title("ğŸ“š ì „ìë„ì„œê´€ í†µí•©ê²€ìƒ‰")
query_params = st.query_params
url_keyword = query_params.get("search", "")
keyword = st.text_input("ì±… ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”", value=url_keyword, placeholder="ì˜ˆ: í–‰ë³µì˜ ê¸°ì›", key="search_input")

if keyword:
    with st.spinner(f"'{keyword}' ê²€ìƒ‰ ì¤‘..."):
        data = search_libraries(keyword)
        
        # 1. ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame(data)
        
        # 2. ì»¬ëŸ¼ëª… ë³€ê²½ (í™”ë©´ í‘œì‹œìš©)
        df.columns = ["ë„ì„œê´€ ì´ë¦„", "ì†Œì¥ í˜„í™©", "URL"]
        
        # 3. ë°ì´í„°í”„ë ˆì„ ì¶œë ¥ (st.column_config ì‚¬ìš©)
        # ì´ ë°©ì‹ì€ ëª¨ë°”ì¼ì—ì„œë„ ê°€ë¡œ ë ˆì´ì•„ì›ƒì´ ê¹¨ì§€ì§€ ì•Šê³  'ë§í¬'ë¥¼ ë²„íŠ¼ì²˜ëŸ¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.
        st.data_editor(
            df,
            column_config={
                "ë„ì„œê´€ ì´ë¦„": st.column_config.TextColumn("ë„ì„œê´€ ì´ë¦„", width="medium"),
                "ì†Œì¥ í˜„í™©": st.column_config.TextColumn("ì†Œì¥ í˜„í™©", width="small"),
                "URL": st.column_config.LinkColumn("ì´ë™", display_text="ì—´ê¸°"),
            },
            hide_index=True,
            use_container_width=True,
            disabled=True # í¸ì§‘ ë¶ˆê°€ëŠ¥í•˜ê²Œ ì„¤ì •
        )
