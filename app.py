import streamlit as st
import requests
from lxml import html
import re
from urllib.parse import quote

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë„ì„œê´€ í†µí•© ê²€ìƒ‰", page_icon="ğŸ“š")

# ë„ì„œê´€ ë°ì´í„° ì„¤ì •
libraries = [
    {"name": "ì„±ë‚¨ì‹œ ì „ìë„ì„œê´€", "url": "https://vodbook.snlib.go.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8", "type": "ink"},
    {"name": "ê²½ê¸°ëŒ€í•™êµ", "url": "https://ebook.kyonggi.ac.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8", "type": "ink"},
    {"name": "ìš©ì¸ì‹œ ì „ìì±…ë„ì„œê´€", "url": "https://ebook.yongin.go.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8", "type": "ink"},
    {"name": "ìˆ˜ì›ì‹œ ì „ìë„ì„œê´€", "url": "https://ebook.suwonlib.go.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8", "type": "ink"},
    {"name": "ê³ ì–‘ì‹œ ë„ì„œê´€ì„¼í„°", "url": "https://ebook.goyanglib.or.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8", "type": "ink"},
    {"name": "ê°•ë‚¨êµ¬ ì „ìë„ì„œê´€", "url": "https://ebook.gangnam.go.kr/elibbook/book_info.asp", "key_param": "strSearch", "xpath": '//*[@id="container"]/div[1]/div[2]/div[1]/div/div[2]/div[1]/div[1]/div/strong/text()', "encoding": "euc-kr", "type": "gangnam"},
    # ì„œì´ˆêµ¬ëŠ” íŠ¹ë³„ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œì™¸í•˜ê³  ë³„ë„ ë¡œì§ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
]

def get_count(tree, xpath_query):
    try:
        nodes = tree.xpath(xpath_query)
        if nodes:
            combined_text = "".join(nodes)
            count_match = re.findall(r'\d+', combined_text)
            return int(count_match[0]) if count_match else 0
    except:
        pass
    return 0

def search_all_libraries(book_name):
    results = []
    progress_bar = st.progress(0)
    
    # ì„œì´ˆêµ¬ë¥¼ ì œì™¸í•œ ì¼ë°˜ ë„ì„œê´€ë“¤ ì²˜ë¦¬
    for i, lib in enumerate(libraries):
        progress_bar.progress((i + 1) / (len(libraries) + 1))
        try:
            encoded_query = quote(book_name.encode(lib["encoding"]))
            if lib["type"] == "gangnam":
                search_url = f"{lib['url']}?{lib['key_param']}={encoded_query}&search=title"
            else:
                search_url = f"{lib['url']}?{lib['key_param']}={encoded_query}&schClst=ctts%2Cautr&schDvsn=001"

            resp = requests.get(search_url, timeout=7)
            count = get_count(html.fromstring(resp.content), lib["xpath"]) if resp.status_code == 200 else 0
            display = f"[{count}ê¶Œ ë°œê²¬]({search_url})" if count > 0 else "ì—†ìŒ"
            results.append({"ë„ì„œê´€": lib['name'], "ê²°ê³¼": display})
        except:
            results.append({"ë„ì„œê´€": lib['name'], "ê²°ê³¼": "ì—ëŸ¬ë°œìƒ"})

    # ì„œì´ˆêµ¬ ì „ìë„ì„œê´€ íŠ¹ë³„ ì²˜ë¦¬ (ì „ìì±…/êµ¬ë…í˜• êµ¬ë¶„)
    try:
        seocho_url = f"https://e-book.seocholib.or.kr/search?keyword={quote(book_name)}"
        resp = requests.get(seocho_url, timeout=7)
        if resp.status_code == 200:
            tree = html.fromstring(resp.content)
            
            # ì„œì´ˆêµ¬ ì†Œì¥í˜•(ì „ìì±…) ì¶”ì¶œ - ë³´í†µ ì²« ë²ˆì§¸ íƒ­ í˜¹ì€ íŠ¹ì • í´ë˜ìŠ¤
            # ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°ìƒ 'ì†Œì¥í˜•'ê³¼ 'êµ¬ë…í˜•' í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ìš”ì†Œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            eb_count = get_count(tree, '//li[contains(., "ì†Œì¥í˜•")]//span/text() | //div[contains(@class, "search-result-count")]//strong/text()')
            # ì„œì´ˆêµ¬ êµ¬ë…í˜• ì¶”ì¶œ (êµ¬ì¡°ì— ë”°ë¼ XPath ì¡°ì • í•„ìš”í•  ìˆ˜ ìˆìŒ)
            sub_count = get_count(tree, '//li[contains(., "êµ¬ë…í˜•")]//span/text()')
            
            results.append({"ë„ì„œê´€": "ì„œì´ˆêµ¬ ë„ì„œê´€(ì „ìì±…)", "ê²°ê³¼": f"[{eb_count}ê¶Œ ë°œê²¬]({seocho_url})" if eb_count > 0 else "ì—†ìŒ"})
            results.append({"ë„ì„œê´€": "ì„œì´ˆêµ¬ ë„ì„œê´€(êµ¬ë…í˜•)", "ê²°ê³¼": f"[{sub_count}ê¶Œ ë°œê²¬]({seocho_url}&contentType=SUBS)" if sub_count > 0 else "ì—†ìŒ"})
        else:
            results.append({"ë„ì„œê´€": "ì„œì´ˆêµ¬ ë„ì„œê´€", "ê²°ê³¼": "ì ‘ì†ë¶ˆê°€"})
    except:
        results.append({"ë„ì„œê´€": "ì„œì´ˆêµ¬ ë„ì„œê´€", "ê²°ê³¼": "ì—ëŸ¬ë°œìƒ"})

    progress_bar.empty()
    return results

# í™”ë©´ êµ¬ì„±
st.title("ğŸ“š ë„ì„œê´€ í†µí•© ê²€ìƒ‰ê¸°")
st.write("ì±… ì œëª©ì„ ì…ë ¥í•˜ê³  **ì—”í„°(Enter)**ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
st.markdown("---")

keyword = st.text_input("ì±… ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: í–‰ë³µì˜ ê¸°ì›", key="search_input")

if keyword:
    with st.spinner(f"'{keyword}' ê²€ìƒ‰ ì¤‘..."):
        res = search_all_libraries(keyword)
        
        st.success(f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.")
        col1, col2 = st.columns([2, 1])
        col1.write("**ë„ì„œê´€ ì´ë¦„**")
        col2.write("**ì†Œì¥ í˜„í™© (í´ë¦­ ì‹œ ì´ë™)**")
        st.divider()

        for item in res:
            c1, c2 = st.columns([2, 1])
            c1.write(item["ë„ì„œê´€"])
            c2.markdown(item["ê²°ê³¼"])
