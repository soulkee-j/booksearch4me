import streamlit as st
import requests
from lxml import html
import re
from urllib.parse import quote

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë„ì„œê´€ í†µí•© ê²€ìƒ‰", page_icon="ğŸ“š")

# ë„ì„œê´€ ë°ì´í„° ì„¤ì •
libraries = [
    {"name": "ì„±ë‚¨ì‹œ ì „ìë„ì„œê´€", "url": "https://vodbook.snlib.go.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8"},
    {"name": "ê²½ê¸°ëŒ€í•™êµ", "url": "https://ebook.kyonggi.ac.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8"},
    {"name": "ìš©ì¸ì‹œ ì „ìì±…ë„ì„œê´€", "url": "https://ebook.yongin.go.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8"},
    {"name": "ìˆ˜ì›ì‹œ ì „ìë„ì„œê´€", "url": "https://ebook.suwonlib.go.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8"},
    {"name": "ê³ ì–‘ì‹œ ë„ì„œê´€ì„¼í„°", "url": "https://ebook.goyanglib.or.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8"},
    {"name": "ê°•ë‚¨êµ¬ ì „ìë„ì„œê´€", "url": "https://ebook.gangnam.go.kr/elibbook/book_info.asp", "key_param": "strSearch", "xpath": '//*[@id="container"]/div[1]/div[2]/div[1]/div/div[2]/div[1]/div[1]/div/strong/text()', "encoding": "euc-kr"}
]

def search_books(book_name):
    results = []
    progress_bar = st.progress(0)
    total = len(libraries)

    for i, lib in enumerate(libraries):
        progress_bar.progress((i + 1) / total)
        try:
            if lib["name"] == "ê°•ë‚¨êµ¬ ì „ìë„ì„œê´€":
                encoded = quote(book_name.encode('euc-kr'))
                search_url = f"{lib['url']}?{lib['key_param']}={encoded}&search=title"
            else:
                encoded = quote(book_name.encode('utf-8'))
                search_url = f"{lib['url']}?{lib['key_param']}={encoded}&schClst=ctts%2Cautr&schDvsn=001"

            resp = requests.get(search_url, timeout=5)
            if resp.status_code == 200:
                tree = html.fromstring(resp.content)
                texts = tree.xpath(lib["xpath"])
                if texts:
                    count_match = re.findall(r'\d+', texts[0].strip())
                    count = int(count_match[0]) if count_match else 0
                    result_display = f"[{count}ê¶Œ ë°œê²¬]({search_url})" if count > 0 else "ì—†ìŒ"
                else:
                    result_display = "ì—†ìŒ"
            else:
                result_display = "ì ‘ì†ë¶ˆê°€"
        except:
            result_display = "ì—ëŸ¬ë°œìƒ"
        results.append({"ë„ì„œê´€": lib['name'], "ê²°ê³¼": result_display})
    progress_bar.empty()
    return results

# í™”ë©´ êµ¬ì„±
st.title("ğŸ“š ë„ì„œê´€ í†µí•© ê²€ìƒ‰ê¸°")
st.write("ì±… ì œëª©ì„ ì…ë ¥í•œ ë’¤ **ì—”í„°(Enter)**ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
st.markdown("---")

# ì…ë ¥ì°½ (on_changeë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë°”ë¡œ ì‹¤í–‰ë˜ëŠ” êµ¬ì¡°)
keyword = st.text_input("ì±… ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: í–‰ë³µì˜ ê¸°ì›", key="search_input")

# ê¸€ìê°€ ì…ë ¥ëœ ìƒíƒœì—ì„œ ì—”í„°ê°€ ì³ì§€ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.
if keyword:
    with st.spinner(f"'{keyword}' ê²€ìƒ‰ ì¤‘..."):
        res = search_books(keyword)
        
        st.success(f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.")
        col1, col2 = st.columns([2, 1])
        col1.write("**ë„ì„œê´€ ì´ë¦„**")
        col2.write("**ì†Œì¥ í˜„í™© (í´ë¦­ ì‹œ ì´ë™)**")
        st.divider()

        for item in res:
            c1, c2 = st.columns([2, 1])
            c1.write(item["ë„ì„œê´€"])
            c2.markdown(item["ê²°ê³¼"])
